{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tester\n",
    "Test if PyTorch was installed correctly, and if CUDA devices are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1338, 0.9017, 0.2004],\n",
      "        [0.0978, 0.3711, 0.3531],\n",
      "        [0.7188, 0.7160, 0.8460],\n",
      "        [0.2020, 0.4699, 0.4234],\n",
      "        [0.1393, 0.0069, 0.8074]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def cls_predictor(num_inputs, num_anchors, num_classes):\n",
    "    return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1),\n",
    "                     kernel_size=3, padding=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_predictor(num_inputs, num_anchors):\n",
    "    return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x, block):\n",
    "    return block(x)\n",
    "\n",
    "\n",
    "Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))\n",
    "Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))\n",
    "Y1.shape, Y2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_pred(pred):\n",
    "    return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)\n",
    "\n",
    "\n",
    "def concat_preds(preds):\n",
    "    return torch.cat([flatten_pred(p) for p in preds], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25300])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_preds([Y1, Y2]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_blk(in_channels, out_channels):\n",
    "    blk = []\n",
    "    for _ in range(2):\n",
    "        blk.append(nn.Conv2d(in_channels, out_channels,\n",
    "                             kernel_size=3, padding=1))\n",
    "        blk.append(nn.BatchNorm2d(out_channels))\n",
    "        blk.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    blk.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*blk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 10, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_net():\n",
    "    blk = []\n",
    "    num_filters = [3, 16, 32, 64]\n",
    "    for i in range(len(num_filters) - 1):\n",
    "        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "\n",
    "forward(torch.zeros((2, 3, 256, 256)), base_net()).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blk(i):\n",
    "    if i == 0:\n",
    "        blk = base_net()\n",
    "    elif i == 1:\n",
    "        blk = down_sample_blk(64, 128)\n",
    "    elif i == 4:\n",
    "        blk = nn.AdaptiveMaxPool2d((1, 1))\n",
    "    else:\n",
    "        blk = down_sample_blk(128, 128)\n",
    "    return blk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
    "    Y = blk(X)\n",
    "    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)\n",
    "    cls_preds = cls_predictor(Y)\n",
    "    bbox_preds = bbox_predictor(Y)\n",
    "    return (Y, anchors, cls_preds, bbox_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_net():\n",
    "    blk = []\n",
    "    num_filters = [3, 16, 32, 64]\n",
    "    for i in range(len(num_filters) - 1):\n",
    "        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "\n",
    "forward(torch.zeros((2, 3, 256, 256)), base_net()).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
    "         [0.88, 0.961]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "num_anchors = len(sizes[0]) + len(ratios[0]) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySSD(nn.Module):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(TinySSD, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        idx_to_in_channels = [64, 128, 128, 128, 128]\n",
    "        for i in range(5):\n",
    "            # Equivalent to the assignment statement `self.blk_i = get_blk(i)`\n",
    "            setattr(self, f'blk_{i}', get_blk(i))\n",
    "            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i],\n",
    "                                                    num_anchors, num_classes))\n",
    "            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i],\n",
    "                                                      num_anchors))\n",
    "\n",
    "    def forward(self, X):\n",
    "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
    "        for i in range(5):\n",
    "            # Here `getattr(self, 'blk_%d' % i)` accesses `self.blk_i`\n",
    "            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(\n",
    "                X, getattr(self, f'blk_{i}'), sizes[i], ratios[i],\n",
    "                getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}'))\n",
    "        anchors = torch.cat(anchors, dim=1)\n",
    "        cls_preds = concat_preds(cls_preds)\n",
    "        cls_preds = cls_preds.reshape(\n",
    "            cls_preds.shape[0], -1, self.num_classes + 1)\n",
    "        bbox_preds = concat_preds(bbox_preds)\n",
    "        return anchors, cls_preds, bbox_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output anchors: torch.Size([1, 5444, 4])\n",
      "output class preds: torch.Size([32, 5444, 2])\n",
      "output bbox preds: torch.Size([32, 21776])\n"
     ]
    }
   ],
   "source": [
    "net = TinySSD(num_classes=1)\n",
    "X = torch.zeros((32, 3, 256, 256))\n",
    "anchors, cls_preds, bbox_preds = net(X)\n",
    "\n",
    "print('output anchors:', anchors.shape)\n",
    "print('output class preds:', cls_preds.shape)\n",
    "print('output bbox preds:', bbox_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RisikoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_dir: str, mode: str, transform=None):\n",
    "        if mode != \"train\" and mode != \"val\" and mode != \"test\":\n",
    "            raise Exception(\"Mode value of dataset not valid\")\n",
    "\n",
    "        self.imgs_dir = dataset_dir + \"/\" + mode + \"/images\"\n",
    "        self.annots_dir = dataset_dir + \"/\" + mode + \"/labels\"\n",
    "\n",
    "        self.annotations = sorted(filter(lambda x: os.path.isfile(\n",
    "            os.path.join(self.annots_dir, x)), os.listdir(self.annots_dir)))\n",
    "        self.images = sorted(filter(lambda x: os.path.isfile(\n",
    "            os.path.join(self.imgs_dir, x)), os.listdir(self.imgs_dir)))\n",
    "        self.transform = transform\n",
    "\n",
    "        if len(self.annotations) != len(self.images):\n",
    "            raise Exception(\n",
    "                \"Number of annotations is different from the number of images\")\n",
    "\n",
    "        for i in range(len(self.annotations)):\n",
    "            if os.path.splitext(os.path.basename(self.annotations[i]))[0] != os.path.splitext(os.path.basename(self.images[i]))[0]:\n",
    "                raise Exception(\"Mismatch between images and annotations at id \" + str(i) + \".   imgName = \" + os.path.splitext(\n",
    "                    os.path.basename(self.images[i]))[0] + \"   labelName = \" + os.path.splitext(os.path.basename(self.annotations[i]))[0])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        annotations_file_data = np.genfromtxt(\n",
    "            fname=self.annots_dir + \"/\" + self.annotations[idx], delimiter=' ', dtype=np.float32)\n",
    "        classes, bboxes = np.hsplit(annotations_file_data, np.array([1]))\n",
    "        for i in range(bboxes.shape[0]):\n",
    "            bbox = bboxes[i]\n",
    "\n",
    "            x0 = bbox[0] - bbox[2] / 2\n",
    "            x1 = bbox[0] + bbox[2] / 2\n",
    "            y0 = bbox[1] - bbox[3] / 2\n",
    "            y1 = bbox[1] + bbox[3] / 2\n",
    "        bboxes = torch.tensor([x0, y0, x1, y1])\n",
    "\n",
    "        #print((torch.from_numpy(classes).type(\n",
    "        #    torch.IntTensor), torch.from_numpy(bboxes)))\n",
    "        output_dict = torch.concat((torch.from_numpy(classes).type(\n",
    "            torch.IntTensor), bboxes), 1)\n",
    "        #print(output_dict)\n",
    "\n",
    "        img = Image.open(self.imgs_dir + \"/\" + self.images[idx]).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img.float(), output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1000 training examples\n",
      "read 100 validation examples\n"
     ]
    }
   ],
   "source": [
    "train_iter, _ = d2l.load_data_bananas(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_iter, new_val_iter= train_loader(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana train\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7efc742065c0>\n",
      "tensor([[[ 20.,  21.,  22.,  ..., 186., 183., 182.],\n",
      "         [ 26.,  22.,  21.,  ..., 187., 186., 183.],\n",
      "         [ 21.,  17.,  18.,  ..., 188., 186., 185.],\n",
      "         ...,\n",
      "         [166., 139., 155.,  ...,  80.,  70.,  17.],\n",
      "         [111., 123., 128.,  ...,  50.,  62.,  22.],\n",
      "         [133., 150., 152.,  ...,  18.,  24.,  22.]],\n",
      "\n",
      "        [[ 27.,  26.,  23.,  ..., 248., 247., 246.],\n",
      "         [ 32.,  28.,  25.,  ..., 249., 247., 247.],\n",
      "         [ 29.,  26.,  27.,  ..., 250., 247., 246.],\n",
      "         ...,\n",
      "         [153., 124., 135.,  ..., 100.,  88.,  35.],\n",
      "         [ 75.,  93., 109.,  ...,  68.,  77.,  37.],\n",
      "         [ 85., 113., 133.,  ...,  35.,  38.,  36.]],\n",
      "\n",
      "        [[ 20.,  22.,  27.,  ..., 245., 247., 248.],\n",
      "         [ 28.,  26.,  26.,  ..., 246., 248., 249.],\n",
      "         [ 31.,  25.,  22.,  ..., 249., 250., 251.],\n",
      "         ...,\n",
      "         [ 51.,  23.,  36.,  ...,  47.,  40.,   0.],\n",
      "         [  0.,   7.,   7.,  ...,  30.,  44.,   4.],\n",
      "         [ 21.,  35.,  30.,  ...,   3.,  12.,  11.]]])\n",
      "tensor([[0.0000, 0.6289, 0.3086, 0.8125, 0.5039]])\n",
      "tensor([[[  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   1.],\n",
      "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "         ...,\n",
      "         [  1.,   0.,   0.,  ...,   1.,   0.,   0.],\n",
      "         [  1.,   1.,   0.,  ...,   1.,   0.,   0.],\n",
      "         [  1.,   0.,   0.,  ...,   1.,   0.,   0.]],\n",
      "\n",
      "        [[128., 128., 128.,  ..., 126., 126., 126.],\n",
      "         [128., 128., 128.,  ..., 128., 128., 127.],\n",
      "         [128., 128., 128.,  ..., 127., 127., 127.],\n",
      "         ...,\n",
      "         [134., 133., 133.,  ..., 133., 132., 132.],\n",
      "         [134., 134., 133.,  ..., 133., 132., 132.],\n",
      "         [134., 133., 133.,  ..., 133., 132., 132.]],\n",
      "\n",
      "        [[205., 205., 205.,  ..., 203., 203., 203.],\n",
      "         [205., 205., 205.,  ..., 205., 205., 204.],\n",
      "         [205., 205., 205.,  ..., 204., 204., 204.],\n",
      "         ...,\n",
      "         [209., 208., 208.,  ..., 208., 207., 207.],\n",
      "         [209., 209., 208.,  ..., 208., 207., 207.],\n",
      "         [209., 208., 208.,  ..., 208., 207., 207.]]])\n",
      "tensor([[0.0000, 0.2969, 0.4727, 0.5508, 0.6992]])\n",
      "tensor([[[226., 232., 234.,  ...,  18.,   6.,  28.],\n",
      "         [227., 231., 231.,  ...,  83.,  22.,  26.],\n",
      "         [227., 231., 231.,  ...,  26.,   9.,  15.],\n",
      "         ...,\n",
      "         [  7.,   4.,   5.,  ..., 125., 107.,  94.],\n",
      "         [  5.,  25.,   3.,  ...,  93., 119., 163.],\n",
      "         [  2.,   4.,  13.,  ..., 148., 168., 161.]],\n",
      "\n",
      "        [[223., 231., 233.,  ...,  14.,   6.,  29.],\n",
      "         [224., 230., 232.,  ...,  80.,  18.,  23.],\n",
      "         [226., 230., 231.,  ...,  19.,   0.,   5.],\n",
      "         ...,\n",
      "         [  3.,   0.,   1.,  ...,  67.,  58.,  48.],\n",
      "         [  4.,  24.,   2.,  ...,  50.,  73., 115.],\n",
      "         [  2.,   4.,  12.,  ..., 113., 122., 112.]],\n",
      "\n",
      "        [[218., 226., 229.,  ...,  11.,   0.,  13.],\n",
      "         [219., 225., 227.,  ...,  75.,   7.,   8.],\n",
      "         [222., 226., 229.,  ...,  11.,   0.,   0.],\n",
      "         ...,\n",
      "         [  2.,   0.,   0.,  ...,  27.,  26.,  22.],\n",
      "         [  2.,  22.,   0.,  ...,  18.,  39.,  79.],\n",
      "         [  0.,   2.,   8.,  ...,  85.,  86.,  71.]]])\n",
      "tensor([[0.0000, 0.7070, 0.3438, 0.9727, 0.5547]])\n",
      "tensor([[[175., 175., 173.,  ..., 162., 163., 163.],\n",
      "         [175., 175., 174.,  ..., 163., 162., 163.],\n",
      "         [172., 173., 174.,  ..., 164., 163., 163.],\n",
      "         ...,\n",
      "         [221., 224., 225.,  ..., 189., 170., 163.],\n",
      "         [220., 225., 226.,  ..., 208., 186., 172.],\n",
      "         [224., 223., 220.,  ..., 206., 186., 182.]],\n",
      "\n",
      "        [[202., 202., 201.,  ..., 194., 195., 195.],\n",
      "         [202., 202., 202.,  ..., 195., 194., 195.],\n",
      "         [200., 201., 202.,  ..., 196., 195., 195.],\n",
      "         ...,\n",
      "         [195., 198., 201.,  ..., 169., 150., 143.],\n",
      "         [194., 199., 200.,  ..., 188., 166., 152.],\n",
      "         [198., 197., 194.,  ..., 186., 166., 162.]],\n",
      "\n",
      "        [[223., 223., 222.,  ..., 215., 216., 216.],\n",
      "         [223., 223., 223.,  ..., 216., 215., 216.],\n",
      "         [221., 222., 223.,  ..., 217., 216., 216.],\n",
      "         ...,\n",
      "         [162., 165., 167.,  ..., 142., 123., 116.],\n",
      "         [159., 164., 165.,  ..., 161., 141., 127.],\n",
      "         [163., 162., 159.,  ..., 159., 141., 137.]]])\n",
      "tensor([[0.0000, 0.6250, 0.0547, 0.8125, 0.2383]])\n",
      "tensor([[[ 69.,  68.,  68.,  ..., 169., 166., 163.],\n",
      "         [ 69.,  68.,  68.,  ..., 164., 160., 157.],\n",
      "         [ 65.,  65.,  64.,  ..., 164., 162., 162.],\n",
      "         ...,\n",
      "         [ 63.,  57.,  61.,  ..., 178., 182., 174.],\n",
      "         [ 63.,  61.,  53.,  ..., 179., 176., 183.],\n",
      "         [ 68.,  59.,  60.,  ..., 172., 181., 175.]],\n",
      "\n",
      "        [[ 79.,  78.,  78.,  ..., 149., 148., 146.],\n",
      "         [ 79.,  78.,  78.,  ..., 146., 143., 142.],\n",
      "         [ 74.,  74.,  75.,  ..., 149., 149., 149.],\n",
      "         ...,\n",
      "         [ 66.,  60.,  64.,  ..., 155., 156., 148.],\n",
      "         [ 66.,  64.,  56.,  ..., 156., 150., 157.],\n",
      "         [ 71.,  62.,  63.,  ..., 150., 155., 149.]],\n",
      "\n",
      "        [[106., 105., 105.,  ..., 138., 138., 138.],\n",
      "         [106., 105., 105.,  ..., 136., 135., 135.],\n",
      "         [103., 103., 103.,  ..., 142., 143., 143.],\n",
      "         ...,\n",
      "         [ 71.,  65.,  69.,  ..., 139., 141., 133.],\n",
      "         [ 71.,  69.,  61.,  ..., 142., 135., 142.],\n",
      "         [ 76.,  67.,  68.,  ..., 136., 140., 134.]]])\n",
      "tensor([[0.0000, 0.1758, 0.6016, 0.4492, 0.8125]])\n",
      "tensor([[[255., 255., 244.,  ...,  85.,  92.,  57.],\n",
      "         [198., 113.,  85.,  ...,  93., 109.,  97.],\n",
      "         [ 85.,  77.,  83.,  ..., 134.,  84., 103.],\n",
      "         ...,\n",
      "         [ 30.,  31.,  14.,  ...,  35.,  29.,  28.],\n",
      "         [ 57.,  57.,  56.,  ...,  19.,  23.,  26.],\n",
      "         [ 45.,  47.,  58.,  ...,  31.,  17.,  16.]],\n",
      "\n",
      "        [[255., 253., 238.,  ...,  66.,  76.,  40.],\n",
      "         [194., 109.,  79.,  ...,  70.,  88.,  78.],\n",
      "         [ 76.,  70.,  76.,  ..., 105.,  57.,  77.],\n",
      "         ...,\n",
      "         [ 27.,  28.,  12.,  ...,  31.,  24.,  25.],\n",
      "         [ 48.,  49.,  48.,  ...,  12.,  18.,  21.],\n",
      "         [ 34.,  36.,  47.,  ...,  24.,  10.,  11.]],\n",
      "\n",
      "        [[222., 220., 206.,  ...,  33.,  43.,  10.],\n",
      "         [157.,  72.,  43.,  ...,  38.,  57.,  48.],\n",
      "         [ 35.,  26.,  30.,  ...,  75.,  28.,  50.],\n",
      "         ...,\n",
      "         [ 10.,  13.,   0.,  ...,  22.,  18.,  20.],\n",
      "         [ 31.,  30.,  25.,  ...,   4.,  12.,  15.],\n",
      "         [ 16.,  14.,  19.,  ...,  14.,   4.,   5.]]])\n",
      "tensor([[0.0000, 0.3125, 0.4961, 0.4805, 0.6602]])\n",
      "tensor([[[43., 92., 53.,  ..., 64., 72., 56.],\n",
      "         [58., 72., 62.,  ..., 51., 73., 65.],\n",
      "         [68., 82., 51.,  ..., 63., 63., 68.],\n",
      "         ...,\n",
      "         [21., 37., 31.,  ..., 34., 33., 43.],\n",
      "         [12., 22., 55.,  ..., 62., 63., 76.],\n",
      "         [24.,  5., 36.,  ..., 81., 80., 74.]],\n",
      "\n",
      "        [[35., 88., 52.,  ..., 85., 87., 68.],\n",
      "         [52., 68., 63.,  ..., 76., 89., 80.],\n",
      "         [67., 83., 54.,  ..., 92., 84., 87.],\n",
      "         ...,\n",
      "         [41., 60., 54.,  ..., 41., 40., 50.],\n",
      "         [29., 39., 72.,  ..., 67., 68., 81.],\n",
      "         [40., 22., 50.,  ..., 86., 83., 77.]],\n",
      "\n",
      "        [[24., 77., 48.,  ..., 66., 66., 46.],\n",
      "         [38., 57., 57.,  ..., 47., 62., 51.],\n",
      "         [47., 67., 47.,  ..., 48., 41., 42.],\n",
      "         ...,\n",
      "         [16., 34., 28.,  ..., 23., 22., 32.],\n",
      "         [11., 21., 53.,  ..., 47., 48., 61.],\n",
      "         [27.,  6., 33.,  ..., 64., 62., 56.]]])\n",
      "tensor([[0.0000, 0.4180, 0.4688, 0.6523, 0.7031]])\n",
      "tensor([[[205., 216., 214.,  ..., 100., 108., 109.],\n",
      "         [209., 218., 213.,  ..., 105., 107., 108.],\n",
      "         [214., 213., 219.,  ..., 115., 115., 124.],\n",
      "         ...,\n",
      "         [ 29.,  77.,  27.,  ...,  42.,  12.,  18.],\n",
      "         [ 72.,  62.,  44.,  ...,  36.,  11.,  13.],\n",
      "         [ 63.,  86.,  33.,  ...,  36.,  25.,  15.]],\n",
      "\n",
      "        [[208., 219., 217.,  ..., 126., 134., 135.],\n",
      "         [212., 221., 216.,  ..., 130., 131., 133.],\n",
      "         [217., 216., 222.,  ..., 136., 136., 145.],\n",
      "         ...,\n",
      "         [ 39.,  87.,  35.,  ...,  44.,  15.,  21.],\n",
      "         [ 85.,  76.,  55.,  ...,  38.,  12.,  14.],\n",
      "         [ 77., 100.,  44.,  ...,  37.,  26.,  16.]],\n",
      "\n",
      "        [[213., 224., 222.,  ..., 161., 169., 170.],\n",
      "         [217., 226., 221.,  ..., 161., 165., 164.],\n",
      "         [222., 221., 229.,  ..., 163., 165., 172.],\n",
      "         ...,\n",
      "         [ 15.,  62.,  12.,  ...,  30.,   4.,  12.],\n",
      "         [ 55.,  43.,  25.,  ...,  27.,   6.,   8.],\n",
      "         [ 42.,  65.,  10.,  ...,  29.,  20.,  11.]]])\n",
      "tensor([[0.0000, 0.6289, 0.6094, 0.8164, 0.7891]])\n",
      "tensor([[[255., 255., 255.,  ..., 210., 212., 213.],\n",
      "         [255., 255., 255.,  ..., 212., 213., 214.],\n",
      "         [255., 255., 255.,  ..., 213., 214., 214.],\n",
      "         ...,\n",
      "         [ 86.,  85., 120.,  ...,  62.,  58.,  58.],\n",
      "         [ 62., 109., 142.,  ...,  57.,  49.,  56.],\n",
      "         [124., 100., 100.,  ...,  62.,  50.,  62.]],\n",
      "\n",
      "        [[255., 255., 255.,  ..., 244., 246., 247.],\n",
      "         [255., 255., 255.,  ..., 246., 247., 248.],\n",
      "         [255., 255., 255.,  ..., 247., 248., 248.],\n",
      "         ...,\n",
      "         [ 90.,  91., 128.,  ...,  62.,  58.,  58.],\n",
      "         [ 70., 116., 150.,  ...,  57.,  49.,  56.],\n",
      "         [133., 110., 108.,  ...,  62.,  50.,  62.]],\n",
      "\n",
      "        [[255., 255., 255.,  ..., 245., 247., 248.],\n",
      "         [255., 255., 255.,  ..., 247., 248., 249.],\n",
      "         [255., 255., 255.,  ..., 248., 249., 249.],\n",
      "         ...,\n",
      "         [ 63.,  65., 105.,  ...,  62.,  58.,  58.],\n",
      "         [ 31.,  82., 127.,  ...,  57.,  49.,  56.],\n",
      "         [ 88.,  73.,  85.,  ...,  62.,  50.,  62.]]])\n",
      "tensor([[0.0000, 0.5664, 0.6602, 0.7109, 0.8633]])\n",
      "tensor([[[ 37.,  38.,  39.,  ..., 215., 230., 245.],\n",
      "         [ 36.,  37.,  38.,  ..., 203., 223., 245.],\n",
      "         [ 36.,  37.,  38.,  ..., 200., 217., 238.],\n",
      "         ...,\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.],\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.],\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.]],\n",
      "\n",
      "        [[ 35.,  36.,  37.,  ..., 156., 171., 187.],\n",
      "         [ 34.,  35.,  36.,  ..., 143., 164., 187.],\n",
      "         [ 34.,  35.,  36.,  ..., 136., 155., 176.],\n",
      "         ...,\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.],\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.],\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.]],\n",
      "\n",
      "        [[ 48.,  49.,  50.,  ...,  86.,  91., 103.],\n",
      "         [ 47.,  48.,  49.,  ...,  73.,  86., 105.],\n",
      "         [ 45.,  46.,  47.,  ...,  72.,  82.,  99.],\n",
      "         ...,\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.],\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.],\n",
      "         [  1.,   1.,   1.,  ...,   2.,   2.,   2.]]])\n",
      "tensor([[0.0000, 0.4414, 0.7500, 0.6758, 0.9531]])\n",
      "tensor([[[ 76.,  75.,  63.,  ..., 226., 227., 219.],\n",
      "         [ 85.,  75.,  95.,  ..., 219., 203., 206.],\n",
      "         [ 80., 129., 181.,  ..., 209., 202., 195.],\n",
      "         ...,\n",
      "         [125., 105., 100.,  ..., 203., 203., 178.],\n",
      "         [107., 121.,  98.,  ..., 195., 197., 200.],\n",
      "         [ 94., 185., 125.,  ..., 210., 198., 217.]],\n",
      "\n",
      "        [[124., 123., 112.,  ..., 230., 233., 225.],\n",
      "         [128., 118., 137.,  ..., 223., 210., 213.],\n",
      "         [113., 160., 206.,  ..., 216., 209., 202.],\n",
      "         ...,\n",
      "         [113.,  91.,  84.,  ..., 177., 175., 152.],\n",
      "         [ 95., 107.,  82.,  ..., 170., 171., 176.],\n",
      "         [ 82., 173., 109.,  ..., 186., 173., 194.]],\n",
      "\n",
      "        [[160., 161., 155.,  ..., 241., 245., 237.],\n",
      "         [163., 153., 175.,  ..., 234., 220., 223.],\n",
      "         [146., 191., 237.,  ..., 224., 217., 210.],\n",
      "         ...,\n",
      "         [ 73.,  52.,  48.,  ..., 103., 112.,  95.],\n",
      "         [ 53.,  68.,  46.,  ...,  86.,  96., 104.],\n",
      "         [ 40., 133.,  73.,  ...,  96.,  91., 116.]]])\n",
      "tensor([[0.0000, 0.2344, 0.5000, 0.4219, 0.6602]])\n",
      "tensor([[[ 57.,  25.,  24.,  ..., 230., 241., 223.],\n",
      "         [ 28.,  66.,  77.,  ..., 243., 140., 154.],\n",
      "         [ 65.,  33.,  46.,  ..., 174., 210., 142.],\n",
      "         ...,\n",
      "         [ 25.,  50.,  28.,  ...,  45.,  17.,   5.],\n",
      "         [ 38.,  26.,  44.,  ...,  23.,  14.,  27.],\n",
      "         [ 12.,  16.,  23.,  ...,  16.,  22.,  41.]],\n",
      "\n",
      "        [[ 75.,  42.,  38.,  ..., 238., 242., 222.],\n",
      "         [ 46.,  83.,  91.,  ..., 251., 141., 153.],\n",
      "         [ 82.,  49.,  60.,  ..., 182., 211., 140.],\n",
      "         ...,\n",
      "         [ 17.,  42.,  19.,  ...,  47.,  15.,   3.],\n",
      "         [ 30.,  19.,  36.,  ...,  21.,  10.,  21.],\n",
      "         [  6.,  11.,  17.,  ...,  13.,  15.,  33.]],\n",
      "\n",
      "        [[ 25.,   0.,   2.,  ..., 227., 237., 220.],\n",
      "         [  0.,  39.,  55.,  ..., 236., 133., 148.],\n",
      "         [ 40.,  10.,  25.,  ..., 159., 195., 127.],\n",
      "         ...,\n",
      "         [  4.,  29.,   4.,  ...,  26.,   0.,   0.],\n",
      "         [ 27.,  11.,  23.,  ...,   9.,   0.,   9.],\n",
      "         [  6.,   7.,   5.,  ...,   8.,   5.,  22.]]])\n",
      "tensor([[0.0000, 0.2891, 0.7578, 0.4609, 0.9453]])\n",
      "tensor([[[119., 117., 127.,  ..., 105., 108., 107.],\n",
      "         [126., 121., 125.,  ..., 108., 109., 108.],\n",
      "         [125., 124., 127.,  ..., 110., 110., 108.],\n",
      "         ...,\n",
      "         [194., 120.,  80.,  ..., 103., 103., 101.],\n",
      "         [196., 133.,  87.,  ...,  94., 105., 109.],\n",
      "         [179., 126., 104.,  ...,  88.,  95.,  96.]],\n",
      "\n",
      "        [[123., 121., 126.,  ..., 121., 124., 123.],\n",
      "         [127., 122., 124.,  ..., 124., 125., 124.],\n",
      "         [125., 124., 125.,  ..., 126., 125., 123.],\n",
      "         ...,\n",
      "         [164., 100.,  81.,  ..., 116., 118., 116.],\n",
      "         [162., 110.,  85.,  ..., 108., 119., 121.],\n",
      "         [142., 101.,  99.,  ..., 102., 109., 108.]],\n",
      "\n",
      "        [[ 62.,  60.,  69.,  ...,  58.,  59.,  58.],\n",
      "         [ 67.,  62.,  67.,  ...,  61.,  60.,  59.],\n",
      "         [ 63.,  64.,  68.,  ...,  63.,  60.,  56.],\n",
      "         ...,\n",
      "         [ 52.,   1.,  11.,  ...,  62.,  53.,  47.],\n",
      "         [ 54.,  16.,  24.,  ...,  55.,  58.,  55.],\n",
      "         [ 35.,   9.,  44.,  ...,  51.,  48.,  44.]]])\n",
      "tensor([[0.0000, 0.5469, 0.0820, 0.7578, 0.3086]])\n",
      "tensor([[[  7.,   7.,   6.,  ..., 102., 104., 102.],\n",
      "         [  8.,   7.,   3.,  ..., 103., 103., 103.],\n",
      "         [  8.,   5.,   2.,  ..., 100.,  99., 100.],\n",
      "         ...,\n",
      "         [  0.,   4.,   0.,  ..., 164., 167., 156.],\n",
      "         [  0.,   0.,   3.,  ..., 175., 152., 159.],\n",
      "         [  3.,   1.,   5.,  ...,   0.,  33.,   8.]],\n",
      "\n",
      "        [[143., 145., 145.,  ..., 190., 192., 190.],\n",
      "         [144., 145., 144.,  ..., 193., 193., 193.],\n",
      "         [146., 146., 145.,  ..., 192., 191., 192.],\n",
      "         ...,\n",
      "         [  1.,   6.,   1.,  ..., 209., 212., 201.],\n",
      "         [  0.,   0.,   1.,  ..., 208., 185., 192.],\n",
      "         [  1.,   0.,   1.,  ...,  20.,  59.,  34.]],\n",
      "\n",
      "        [[251., 252., 250.,  ..., 253., 255., 253.],\n",
      "         [252., 252., 249.,  ..., 255., 255., 255.],\n",
      "         [253., 252., 250.,  ..., 255., 254., 255.],\n",
      "         ...,\n",
      "         [  0.,   5.,   0.,  ..., 248., 253., 242.],\n",
      "         [  2.,   0.,   2.,  ..., 249., 220., 223.],\n",
      "         [  4.,   2.,   2.,  ...,  60.,  92.,  61.]]])\n",
      "tensor([[0.0000, 0.5234, 0.3438, 0.7461, 0.5977]])\n",
      "tensor([[[113., 119., 128.,  ...,  94.,  87.,  98.],\n",
      "         [109., 116., 124.,  ...,  91., 111., 109.],\n",
      "         [100., 109., 119.,  ..., 104., 127., 138.],\n",
      "         ...,\n",
      "         [  0.,   1.,   1.,  ...,   0.,   2.,   1.],\n",
      "         [  0.,   1.,   1.,  ...,   0.,   2.,   1.],\n",
      "         [  1.,   1.,   2.,  ...,   0.,   2.,   1.]],\n",
      "\n",
      "        [[149., 154., 159.,  ..., 132., 121., 130.],\n",
      "         [146., 152., 156.,  ..., 125., 137., 131.],\n",
      "         [144., 150., 154.,  ..., 130., 141., 144.],\n",
      "         ...,\n",
      "         [ 75.,  76.,  76.,  ...,  83.,  82.,  81.],\n",
      "         [ 75.,  76.,  76.,  ...,  83.,  82.,  81.],\n",
      "         [ 76.,  76.,  77.,  ...,  83.,  82.,  81.]],\n",
      "\n",
      "        [[173., 176., 180.,  ..., 168., 159., 171.],\n",
      "         [172., 176., 179.,  ..., 160., 172., 168.],\n",
      "         [171., 178., 182.,  ..., 165., 170., 170.],\n",
      "         ...,\n",
      "         [ 81.,  82.,  82.,  ...,  93.,  93.,  92.],\n",
      "         [ 81.,  82.,  82.,  ...,  93.,  93.,  92.],\n",
      "         [ 82.,  82.,  83.,  ...,  93.,  93.,  92.]]])\n",
      "tensor([[0.0000, 0.2422, 0.2109, 0.3906, 0.4180]])\n",
      "tensor([[[ 54.,  95., 114.,  ..., 221., 219., 225.],\n",
      "         [ 83.,  59.,  83.,  ..., 217., 219., 204.],\n",
      "         [ 57.,  91.,  94.,  ..., 226., 221., 233.],\n",
      "         ...,\n",
      "         [146., 145., 117.,  ..., 121., 181., 142.],\n",
      "         [138., 194., 149.,  ..., 107., 148., 168.],\n",
      "         [149., 189., 118.,  ..., 187., 151., 138.]],\n",
      "\n",
      "        [[116., 155., 164.,  ..., 210., 208., 214.],\n",
      "         [140., 115., 135.,  ..., 206., 208., 193.],\n",
      "         [106., 143., 145.,  ..., 215., 210., 222.],\n",
      "         ...,\n",
      "         [141., 140., 112.,  ..., 118., 180., 141.],\n",
      "         [133., 189., 144.,  ..., 106., 147., 167.],\n",
      "         [144., 184., 113.,  ..., 188., 150., 137.]],\n",
      "\n",
      "        [[ 15.,  59.,  79.,  ..., 204., 202., 208.],\n",
      "         [ 45.,  24.,  53.,  ..., 200., 202., 187.],\n",
      "         [ 24.,  61.,  70.,  ..., 209., 204., 216.],\n",
      "         ...,\n",
      "         [147., 146., 118.,  ..., 125., 186., 147.],\n",
      "         [139., 195., 148.,  ..., 112., 155., 175.],\n",
      "         [150., 190., 117.,  ..., 193., 158., 145.]]])\n",
      "tensor([[0.0000, 0.4219, 0.5820, 0.6758, 0.8203]])\n",
      "tensor([[[184., 184., 183.,  ..., 214., 215., 218.],\n",
      "         [185., 188., 188.,  ..., 216., 214., 213.],\n",
      "         [190., 187., 185.,  ..., 213., 212., 209.],\n",
      "         ...,\n",
      "         [ 53.,   0.,   0.,  ...,  52., 116., 100.],\n",
      "         [ 52.,  79.,  59.,  ...,  64.,  76.,  80.],\n",
      "         [  0.,   1.,  48.,  ...,  61., 116.,  85.]],\n",
      "\n",
      "        [[228., 228., 228.,  ..., 240., 241., 244.],\n",
      "         [229., 233., 233.,  ..., 242., 240., 239.],\n",
      "         [232., 229., 227.,  ..., 241., 240., 237.],\n",
      "         ...,\n",
      "         [ 83.,  16.,  20.,  ...,  38., 100.,  83.],\n",
      "         [ 80., 107.,  86.,  ...,  49.,  58.,  60.],\n",
      "         [ 25.,  32.,  79.,  ...,  46.,  95.,  63.]],\n",
      "\n",
      "        [[253., 253., 251.,  ..., 253., 254., 255.],\n",
      "         [254., 255., 255.,  ..., 255., 253., 252.],\n",
      "         [255., 251., 249.,  ..., 253., 252., 249.],\n",
      "         ...,\n",
      "         [109.,  37.,  29.,  ...,   0.,  48.,  27.],\n",
      "         [104., 129., 103.,  ...,   6.,  10.,   9.],\n",
      "         [ 49.,  53.,  99.,  ...,   5.,  50.,  14.]]])\n",
      "tensor([[0.0000, 0.1211, 0.1055, 0.3477, 0.3008]])\n",
      "tensor([[[126., 113.,  81.,  ...,  53.,  54.,  63.],\n",
      "         [ 90.,  87., 106.,  ...,  68.,  82.,  62.],\n",
      "         [ 74.,  81., 117.,  ...,  76.,  79.,  41.],\n",
      "         ...,\n",
      "         [133., 158., 143.,  ...,  60.,  63.,  52.],\n",
      "         [146., 144., 149.,  ...,  54.,  69.,  56.],\n",
      "         [146., 141., 133.,  ...,  58.,  58.,  58.]],\n",
      "\n",
      "        [[136., 122.,  89.,  ...,  53.,  54.,  63.],\n",
      "         [ 99.,  96., 114.,  ...,  68.,  82.,  62.],\n",
      "         [ 82.,  89., 125.,  ...,  76.,  79.,  41.],\n",
      "         ...,\n",
      "         [134., 159., 144.,  ...,  65.,  68.,  57.],\n",
      "         [147., 145., 150.,  ...,  59.,  74.,  61.],\n",
      "         [147., 142., 134.,  ...,  63.,  63.,  63.]],\n",
      "\n",
      "        [[ 50.,  39.,  14.,  ...,  29.,  30.,  37.],\n",
      "         [ 18.,  17.,  39.,  ...,  44.,  58.,  36.],\n",
      "         [  9.,  16.,  50.,  ...,  52.,  55.,  17.],\n",
      "         ...,\n",
      "         [129., 154., 139.,  ...,  33.,  36.,  25.],\n",
      "         [142., 140., 145.,  ...,  29.,  44.,  31.],\n",
      "         [142., 137., 129.,  ...,  33.,  33.,  33.]]])\n",
      "tensor([[0.0000, 0.6523, 0.4492, 0.8594, 0.6250]])\n",
      "tensor([[[ 44.,  44.,  44.,  ...,  31.,  29.,  31.],\n",
      "         [ 36.,  36.,  36.,  ...,  14.,  13.,  16.],\n",
      "         [ 33.,  33.,  34.,  ...,   6.,   5.,   7.],\n",
      "         ...,\n",
      "         [255., 255., 255.,  ..., 141., 135., 139.],\n",
      "         [254., 253., 252.,  ..., 148., 143., 142.],\n",
      "         [248., 253., 253.,  ..., 147., 146., 141.]],\n",
      "\n",
      "        [[143., 143., 143.,  ..., 129., 130., 132.],\n",
      "         [135., 135., 135.,  ..., 117., 118., 121.],\n",
      "         [135., 135., 136.,  ..., 117., 118., 120.],\n",
      "         ...,\n",
      "         [247., 246., 248.,  ..., 161., 155., 159.],\n",
      "         [248., 247., 247.,  ..., 165., 163., 162.],\n",
      "         [246., 249., 248.,  ..., 164., 165., 160.]],\n",
      "\n",
      "        [[208., 208., 208.,  ..., 200., 200., 202.],\n",
      "         [200., 200., 200.,  ..., 186., 186., 189.],\n",
      "         [199., 199., 200.,  ..., 186., 186., 188.],\n",
      "         ...,\n",
      "         [246., 244., 246.,  ..., 186., 180., 184.],\n",
      "         [250., 247., 243.,  ..., 193., 190., 189.],\n",
      "         [249., 248., 244.,  ..., 194., 195., 190.]]])\n",
      "tensor([[0.0000, 0.1133, 0.4609, 0.2852, 0.6758]])\n",
      "tensor([[[177., 177., 177.,  ..., 171., 171., 171.],\n",
      "         [177., 177., 178.,  ..., 171., 171., 171.],\n",
      "         [178., 178., 178.,  ..., 171., 171., 171.],\n",
      "         ...,\n",
      "         [149., 222., 177.,  ..., 203., 210., 192.],\n",
      "         [233., 226., 189.,  ..., 170., 194., 184.],\n",
      "         [217., 242., 192.,  ..., 179., 150., 169.]],\n",
      "\n",
      "        [[217., 217., 217.,  ..., 215., 215., 215.],\n",
      "         [217., 217., 218.,  ..., 215., 215., 215.],\n",
      "         [218., 218., 218.,  ..., 215., 215., 215.],\n",
      "         ...,\n",
      "         [ 42., 120.,  81.,  ..., 113., 125., 112.],\n",
      "         [117., 115.,  89.,  ...,  87., 113., 105.],\n",
      "         [ 96., 127.,  90.,  ...,  99.,  70.,  90.]],\n",
      "\n",
      "        [[253., 253., 253.,  ..., 254., 254., 254.],\n",
      "         [253., 253., 254.,  ..., 254., 254., 254.],\n",
      "         [254., 254., 254.,  ..., 254., 254., 254.],\n",
      "         ...,\n",
      "         [  0.,  72.,  33.,  ...,  61.,  68.,  53.],\n",
      "         [ 70.,  69.,  40.,  ...,  37.,  58.,  48.],\n",
      "         [ 49.,  80.,  41.,  ...,  50.,  17.,  34.]]])\n",
      "tensor([[0.0000, 0.5742, 0.5117, 0.7930, 0.6797]])\n",
      "our train\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7efcc0957220>\n",
      "(tensor([[ 3],\n",
      "        [ 0],\n",
      "        [ 0],\n",
      "        [ 2],\n",
      "        [ 0],\n",
      "        [ 3],\n",
      "        [ 1],\n",
      "        [ 0],\n",
      "        [ 1],\n",
      "        [ 3],\n",
      "        [ 5],\n",
      "        [ 5],\n",
      "        [ 5],\n",
      "        [ 5],\n",
      "        [ 1],\n",
      "        [ 3],\n",
      "        [ 2],\n",
      "        [ 0],\n",
      "        [ 4],\n",
      "        [ 1],\n",
      "        [ 4],\n",
      "        [ 0],\n",
      "        [ 0],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 1],\n",
      "        [ 0],\n",
      "        [ 0],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 3],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 2],\n",
      "        [ 5],\n",
      "        [ 5],\n",
      "        [ 3],\n",
      "        [ 5],\n",
      "        [ 5],\n",
      "        [ 1],\n",
      "        [ 3],\n",
      "        [ 0],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 3],\n",
      "        [ 0],\n",
      "        [ 2],\n",
      "        [ 0],\n",
      "        [ 3],\n",
      "        [ 2],\n",
      "        [ 2],\n",
      "        [ 2],\n",
      "        [ 5],\n",
      "        [ 5],\n",
      "        [ 0],\n",
      "        [ 2],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 4],\n",
      "        [ 2],\n",
      "        [ 5],\n",
      "        [ 0],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 3],\n",
      "        [ 0],\n",
      "        [ 5],\n",
      "        [11],\n",
      "        [ 8],\n",
      "        [11],\n",
      "        [ 9],\n",
      "        [11],\n",
      "        [ 8],\n",
      "        [11]], dtype=torch.int32), tensor([[0.6896, 0.5668, 0.0229, 0.0164],\n",
      "        [0.7417, 0.6668, 0.0250, 0.0227],\n",
      "        [0.3630, 0.5555, 0.0219, 0.0188],\n",
      "        [0.3628, 0.3910, 0.0182, 0.0195],\n",
      "        [0.4102, 0.8594, 0.0120, 0.0344],\n",
      "        [0.4602, 0.2742, 0.0130, 0.0359],\n",
      "        [0.5552, 0.1695, 0.0219, 0.0172],\n",
      "        [0.4201, 0.3996, 0.0141, 0.0211],\n",
      "        [0.6320, 0.3418, 0.0172, 0.0195],\n",
      "        [0.4385, 0.5309, 0.0146, 0.0289],\n",
      "        [0.5526, 0.7309, 0.0125, 0.0305],\n",
      "        [0.7716, 0.5293, 0.0130, 0.0227],\n",
      "        [0.5883, 0.6039, 0.0214, 0.0156],\n",
      "        [0.5776, 0.6918, 0.0177, 0.0258],\n",
      "        [0.3268, 0.3375, 0.0109, 0.0266],\n",
      "        [0.4565, 0.5863, 0.0193, 0.0273],\n",
      "        [0.4909, 0.8527, 0.0141, 0.0180],\n",
      "        [0.7365, 0.4305, 0.0219, 0.0188],\n",
      "        [0.7456, 0.3191, 0.0224, 0.0180],\n",
      "        [0.4195, 0.7152, 0.0224, 0.0133],\n",
      "        [0.6641, 0.4910, 0.0115, 0.0148],\n",
      "        [0.5208, 0.8066, 0.0146, 0.0273],\n",
      "        [0.6276, 0.5078, 0.0146, 0.0172],\n",
      "        [0.5419, 0.6859, 0.0203, 0.0250],\n",
      "        [0.2424, 0.2684, 0.0234, 0.0180],\n",
      "        [0.6594, 0.5977, 0.0198, 0.0281],\n",
      "        [0.4977, 0.2984, 0.0141, 0.0344],\n",
      "        [0.3237, 0.7121, 0.0193, 0.0258],\n",
      "        [0.6094, 0.6371, 0.0146, 0.0367],\n",
      "        [0.5661, 0.7633, 0.0229, 0.0188],\n",
      "        [0.7224, 0.3559, 0.0229, 0.0195],\n",
      "        [0.3992, 0.1738, 0.0130, 0.0336],\n",
      "        [0.5680, 0.4441, 0.0214, 0.0164],\n",
      "        [0.5346, 0.5613, 0.0193, 0.0258],\n",
      "        [0.4391, 0.3090, 0.0198, 0.0227],\n",
      "        [0.6255, 0.2797, 0.0156, 0.0156],\n",
      "        [0.5326, 0.4020, 0.0141, 0.0242],\n",
      "        [0.5758, 0.6496, 0.0120, 0.0195],\n",
      "        [0.5419, 0.4543, 0.0172, 0.0305],\n",
      "        [0.6466, 0.7148, 0.0224, 0.0219],\n",
      "        [0.5841, 0.5793, 0.0224, 0.0164],\n",
      "        [0.7547, 0.4504, 0.0156, 0.0289],\n",
      "        [0.5247, 0.3332, 0.0151, 0.0227],\n",
      "        [0.6125, 0.1227, 0.0135, 0.0250],\n",
      "        [0.3076, 0.2723, 0.0120, 0.0336],\n",
      "        [0.7094, 0.3371, 0.0188, 0.0336],\n",
      "        [0.6841, 0.7078, 0.0245, 0.0250],\n",
      "        [0.3542, 0.5730, 0.0208, 0.0180],\n",
      "        [0.5497, 0.2574, 0.0130, 0.0336],\n",
      "        [0.5148, 0.8984, 0.0151, 0.0156],\n",
      "        [0.6250, 0.4293, 0.0208, 0.0273],\n",
      "        [0.5854, 0.2535, 0.0177, 0.0242],\n",
      "        [0.6581, 0.5035, 0.0203, 0.0195],\n",
      "        [0.5630, 0.1828, 0.0156, 0.0172],\n",
      "        [0.5349, 0.2730, 0.0198, 0.0305],\n",
      "        [0.3911, 0.5324, 0.0104, 0.0305],\n",
      "        [0.5383, 0.3047, 0.0141, 0.0203],\n",
      "        [0.7214, 0.6086, 0.0156, 0.0219],\n",
      "        [0.5565, 0.5594, 0.0234, 0.0172],\n",
      "        [0.3469, 0.8609, 0.0229, 0.0172],\n",
      "        [0.5974, 0.7043, 0.0219, 0.0273],\n",
      "        [0.4729, 0.5949, 0.0167, 0.0320],\n",
      "        [0.2542, 0.3293, 0.0229, 0.0180],\n",
      "        [0.3404, 0.2793, 0.0120, 0.0289],\n",
      "        [0.5094, 0.4711, 0.0156, 0.0234],\n",
      "        [0.7216, 0.5754, 0.0182, 0.0195],\n",
      "        [0.5477, 0.4141, 0.0214, 0.0141],\n",
      "        [0.3870, 0.5535, 0.0240, 0.0227],\n",
      "        [0.7815, 0.6406, 0.0130, 0.0172],\n",
      "        [0.5849, 0.2773, 0.0135, 0.0250],\n",
      "        [0.6023, 0.3898, 0.0224, 0.0172],\n",
      "        [0.5070, 0.2328, 0.0109, 0.0172],\n",
      "        [0.5417, 0.6195, 0.0188, 0.0203],\n",
      "        [0.5805, 0.3516, 0.0234, 0.0141],\n",
      "        [0.4620, 0.7551, 0.0156, 0.0211],\n",
      "        [0.5182, 0.6461, 0.0146, 0.0219],\n",
      "        [0.5172, 0.1988, 0.0198, 0.0289],\n",
      "        [0.5081, 0.1730, 0.0224, 0.0273],\n",
      "        [0.2969, 0.5855, 0.0219, 0.0227],\n",
      "        [0.6253, 0.3562, 0.0214, 0.0219],\n",
      "        [0.2982, 0.6988, 0.0141, 0.0320],\n",
      "        [0.5349, 0.5215, 0.0219, 0.0258]]))\n",
      "tensor([[3.0000e+00, 6.8958e-01, 5.6680e-01, 2.2917e-02, 1.6406e-02],\n",
      "        [0.0000e+00, 7.4167e-01, 6.6680e-01, 2.5000e-02, 2.2656e-02],\n",
      "        [0.0000e+00, 3.6302e-01, 5.5547e-01, 2.1875e-02, 1.8750e-02],\n",
      "        [2.0000e+00, 3.6276e-01, 3.9102e-01, 1.8229e-02, 1.9531e-02],\n",
      "        [0.0000e+00, 4.1016e-01, 8.5938e-01, 1.1979e-02, 3.4375e-02],\n",
      "        [3.0000e+00, 4.6016e-01, 2.7422e-01, 1.3021e-02, 3.5937e-02],\n",
      "        [1.0000e+00, 5.5521e-01, 1.6953e-01, 2.1875e-02, 1.7188e-02],\n",
      "        [0.0000e+00, 4.2005e-01, 3.9961e-01, 1.4062e-02, 2.1094e-02],\n",
      "        [1.0000e+00, 6.3203e-01, 3.4180e-01, 1.7188e-02, 1.9531e-02],\n",
      "        [3.0000e+00, 4.3854e-01, 5.3086e-01, 1.4583e-02, 2.8906e-02],\n",
      "        [5.0000e+00, 5.5260e-01, 7.3086e-01, 1.2500e-02, 3.0469e-02],\n",
      "        [5.0000e+00, 7.7161e-01, 5.2930e-01, 1.3021e-02, 2.2656e-02],\n",
      "        [5.0000e+00, 5.8828e-01, 6.0391e-01, 2.1354e-02, 1.5625e-02],\n",
      "        [5.0000e+00, 5.7760e-01, 6.9180e-01, 1.7708e-02, 2.5781e-02],\n",
      "        [1.0000e+00, 3.2682e-01, 3.3750e-01, 1.0937e-02, 2.6563e-02],\n",
      "        [3.0000e+00, 4.5651e-01, 5.8633e-01, 1.9271e-02, 2.7344e-02],\n",
      "        [2.0000e+00, 4.9089e-01, 8.5273e-01, 1.4062e-02, 1.7969e-02],\n",
      "        [0.0000e+00, 7.3646e-01, 4.3047e-01, 2.1875e-02, 1.8750e-02],\n",
      "        [4.0000e+00, 7.4557e-01, 3.1914e-01, 2.2396e-02, 1.7969e-02],\n",
      "        [1.0000e+00, 4.1953e-01, 7.1523e-01, 2.2396e-02, 1.3281e-02],\n",
      "        [4.0000e+00, 6.6406e-01, 4.9102e-01, 1.1458e-02, 1.4844e-02],\n",
      "        [0.0000e+00, 5.2083e-01, 8.0664e-01, 1.4583e-02, 2.7344e-02],\n",
      "        [0.0000e+00, 6.2760e-01, 5.0781e-01, 1.4583e-02, 1.7188e-02],\n",
      "        [3.0000e+00, 5.4193e-01, 6.8594e-01, 2.0312e-02, 2.5000e-02],\n",
      "        [4.0000e+00, 2.4245e-01, 2.6836e-01, 2.3438e-02, 1.7969e-02],\n",
      "        [1.0000e+00, 6.5938e-01, 5.9766e-01, 1.9792e-02, 2.8125e-02],\n",
      "        [0.0000e+00, 4.9766e-01, 2.9844e-01, 1.4062e-02, 3.4375e-02],\n",
      "        [0.0000e+00, 3.2370e-01, 7.1211e-01, 1.9271e-02, 2.5781e-02],\n",
      "        [3.0000e+00, 6.0938e-01, 6.3711e-01, 1.4583e-02, 3.6719e-02],\n",
      "        [4.0000e+00, 5.6615e-01, 7.6328e-01, 2.2917e-02, 1.8750e-02],\n",
      "        [5.0000e+00, 7.2240e-01, 3.5586e-01, 2.2917e-02, 1.9531e-02],\n",
      "        [4.0000e+00, 3.9922e-01, 1.7383e-01, 1.3021e-02, 3.3594e-02],\n",
      "        [4.0000e+00, 5.6797e-01, 4.4414e-01, 2.1354e-02, 1.6406e-02],\n",
      "        [5.0000e+00, 5.3464e-01, 5.6133e-01, 1.9271e-02, 2.5781e-02],\n",
      "        [3.0000e+00, 4.3906e-01, 3.0898e-01, 1.9792e-02, 2.2656e-02],\n",
      "        [1.0000e+00, 6.2552e-01, 2.7969e-01, 1.5625e-02, 1.5625e-02],\n",
      "        [1.0000e+00, 5.3255e-01, 4.0195e-01, 1.4062e-02, 2.4219e-02],\n",
      "        [1.0000e+00, 5.7578e-01, 6.4961e-01, 1.1979e-02, 1.9531e-02],\n",
      "        [3.0000e+00, 5.4193e-01, 4.5430e-01, 1.7188e-02, 3.0469e-02],\n",
      "        [4.0000e+00, 6.4661e-01, 7.1484e-01, 2.2396e-02, 2.1875e-02],\n",
      "        [4.0000e+00, 5.8411e-01, 5.7930e-01, 2.2396e-02, 1.6406e-02],\n",
      "        [2.0000e+00, 7.5469e-01, 4.5039e-01, 1.5625e-02, 2.8906e-02],\n",
      "        [5.0000e+00, 5.2474e-01, 3.3320e-01, 1.5104e-02, 2.2656e-02],\n",
      "        [5.0000e+00, 6.1250e-01, 1.2266e-01, 1.3542e-02, 2.5000e-02],\n",
      "        [3.0000e+00, 3.0755e-01, 2.7227e-01, 1.1979e-02, 3.3594e-02],\n",
      "        [5.0000e+00, 7.0938e-01, 3.3711e-01, 1.8750e-02, 3.3594e-02],\n",
      "        [5.0000e+00, 6.8411e-01, 7.0781e-01, 2.4479e-02, 2.5000e-02],\n",
      "        [1.0000e+00, 3.5417e-01, 5.7305e-01, 2.0833e-02, 1.7969e-02],\n",
      "        [3.0000e+00, 5.4974e-01, 2.5742e-01, 1.3021e-02, 3.3594e-02],\n",
      "        [0.0000e+00, 5.1484e-01, 8.9844e-01, 1.5104e-02, 1.5625e-02],\n",
      "        [4.0000e+00, 6.2500e-01, 4.2930e-01, 2.0833e-02, 2.7344e-02],\n",
      "        [5.0000e+00, 5.8542e-01, 2.5352e-01, 1.7708e-02, 2.4219e-02],\n",
      "        [3.0000e+00, 6.5807e-01, 5.0352e-01, 2.0312e-02, 1.9531e-02],\n",
      "        [0.0000e+00, 5.6302e-01, 1.8281e-01, 1.5625e-02, 1.7188e-02],\n",
      "        [2.0000e+00, 5.3490e-01, 2.7305e-01, 1.9792e-02, 3.0469e-02],\n",
      "        [0.0000e+00, 3.9115e-01, 5.3242e-01, 1.0417e-02, 3.0469e-02],\n",
      "        [3.0000e+00, 5.3828e-01, 3.0469e-01, 1.4062e-02, 2.0312e-02],\n",
      "        [2.0000e+00, 7.2135e-01, 6.0859e-01, 1.5625e-02, 2.1875e-02],\n",
      "        [2.0000e+00, 5.5651e-01, 5.5937e-01, 2.3438e-02, 1.7188e-02],\n",
      "        [2.0000e+00, 3.4688e-01, 8.6094e-01, 2.2917e-02, 1.7188e-02],\n",
      "        [5.0000e+00, 5.9740e-01, 7.0430e-01, 2.1875e-02, 2.7344e-02],\n",
      "        [5.0000e+00, 4.7292e-01, 5.9492e-01, 1.6667e-02, 3.2031e-02],\n",
      "        [0.0000e+00, 2.5417e-01, 3.2930e-01, 2.2917e-02, 1.7969e-02],\n",
      "        [2.0000e+00, 3.4036e-01, 2.7930e-01, 1.1979e-02, 2.8906e-02],\n",
      "        [4.0000e+00, 5.0937e-01, 4.7109e-01, 1.5625e-02, 2.3438e-02],\n",
      "        [5.0000e+00, 7.2161e-01, 5.7539e-01, 1.8229e-02, 1.9531e-02],\n",
      "        [4.0000e+00, 5.4766e-01, 4.1406e-01, 2.1354e-02, 1.4062e-02],\n",
      "        [2.0000e+00, 3.8698e-01, 5.5352e-01, 2.3958e-02, 2.2656e-02],\n",
      "        [5.0000e+00, 7.8151e-01, 6.4062e-01, 1.3021e-02, 1.7188e-02],\n",
      "        [0.0000e+00, 5.8490e-01, 2.7734e-01, 1.3542e-02, 2.5000e-02],\n",
      "        [4.0000e+00, 6.0234e-01, 3.8984e-01, 2.2396e-02, 1.7188e-02],\n",
      "        [5.0000e+00, 5.0703e-01, 2.3281e-01, 1.0937e-02, 1.7188e-02],\n",
      "        [3.0000e+00, 5.4167e-01, 6.1953e-01, 1.8750e-02, 2.0312e-02],\n",
      "        [0.0000e+00, 5.8047e-01, 3.5156e-01, 2.3438e-02, 1.4062e-02],\n",
      "        [5.0000e+00, 4.6198e-01, 7.5508e-01, 1.5625e-02, 2.1094e-02],\n",
      "        [1.1000e+01, 5.1823e-01, 6.4609e-01, 1.4583e-02, 2.1875e-02],\n",
      "        [8.0000e+00, 5.1719e-01, 1.9883e-01, 1.9792e-02, 2.8906e-02],\n",
      "        [1.1000e+01, 5.0807e-01, 1.7305e-01, 2.2396e-02, 2.7344e-02],\n",
      "        [9.0000e+00, 2.9688e-01, 5.8555e-01, 2.1875e-02, 2.2656e-02],\n",
      "        [1.1000e+01, 6.2526e-01, 3.5625e-01, 2.1354e-02, 2.1875e-02],\n",
      "        [8.0000e+00, 2.9818e-01, 6.9883e-01, 1.4062e-02, 3.2031e-02],\n",
      "        [1.1000e+01, 5.3490e-01, 5.2148e-01, 2.1875e-02, 2.5781e-02]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4520/160284762.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return (img.float(), torch.tensor(output_dict))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[244., 243., 237.,  ..., 255., 255., 255.],\n",
      "          [230., 230., 225.,  ..., 255., 255., 255.],\n",
      "          [202., 203., 202.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [ 71.,  71.,  70.,  ...,  50.,  49.,  49.],\n",
      "          [ 75.,  76.,  73.,  ...,  46.,  44.,  44.],\n",
      "          [ 77.,  77.,  75.,  ...,  42.,  39.,  38.]],\n",
      "\n",
      "         [[242., 241., 235.,  ..., 255., 255., 255.],\n",
      "          [228., 228., 223.,  ..., 255., 255., 255.],\n",
      "          [200., 201., 200.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [ 83.,  83.,  82.,  ...,  73.,  72.,  72.],\n",
      "          [ 85.,  86.,  85.,  ...,  69.,  67.,  67.],\n",
      "          [ 87.,  87.,  87.,  ...,  65.,  62.,  61.]],\n",
      "\n",
      "         [[219., 218., 212.,  ..., 255., 255., 255.],\n",
      "          [205., 205., 200.,  ..., 255., 255., 255.],\n",
      "          [177., 178., 177.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [ 73.,  73.,  72.,  ...,  45.,  44.,  44.],\n",
      "          [ 76.,  77.,  75.,  ...,  41.,  39.,  39.],\n",
      "          [ 78.,  78.,  77.,  ...,  37.,  34.,  33.]]]])\n",
      "tensor([[[3.0000e+00, 6.8958e-01, 5.6680e-01, 2.2917e-02, 1.6406e-02],\n",
      "         [0.0000e+00, 7.4167e-01, 6.6680e-01, 2.5000e-02, 2.2656e-02],\n",
      "         [0.0000e+00, 3.6302e-01, 5.5547e-01, 2.1875e-02, 1.8750e-02],\n",
      "         [2.0000e+00, 3.6276e-01, 3.9102e-01, 1.8229e-02, 1.9531e-02],\n",
      "         [0.0000e+00, 4.1016e-01, 8.5938e-01, 1.1979e-02, 3.4375e-02],\n",
      "         [3.0000e+00, 4.6016e-01, 2.7422e-01, 1.3021e-02, 3.5937e-02],\n",
      "         [1.0000e+00, 5.5521e-01, 1.6953e-01, 2.1875e-02, 1.7188e-02],\n",
      "         [0.0000e+00, 4.2005e-01, 3.9961e-01, 1.4062e-02, 2.1094e-02],\n",
      "         [1.0000e+00, 6.3203e-01, 3.4180e-01, 1.7188e-02, 1.9531e-02],\n",
      "         [3.0000e+00, 4.3854e-01, 5.3086e-01, 1.4583e-02, 2.8906e-02],\n",
      "         [5.0000e+00, 5.5260e-01, 7.3086e-01, 1.2500e-02, 3.0469e-02],\n",
      "         [5.0000e+00, 7.7161e-01, 5.2930e-01, 1.3021e-02, 2.2656e-02],\n",
      "         [5.0000e+00, 5.8828e-01, 6.0391e-01, 2.1354e-02, 1.5625e-02],\n",
      "         [5.0000e+00, 5.7760e-01, 6.9180e-01, 1.7708e-02, 2.5781e-02],\n",
      "         [1.0000e+00, 3.2682e-01, 3.3750e-01, 1.0937e-02, 2.6563e-02],\n",
      "         [3.0000e+00, 4.5651e-01, 5.8633e-01, 1.9271e-02, 2.7344e-02],\n",
      "         [2.0000e+00, 4.9089e-01, 8.5273e-01, 1.4062e-02, 1.7969e-02],\n",
      "         [0.0000e+00, 7.3646e-01, 4.3047e-01, 2.1875e-02, 1.8750e-02],\n",
      "         [4.0000e+00, 7.4557e-01, 3.1914e-01, 2.2396e-02, 1.7969e-02],\n",
      "         [1.0000e+00, 4.1953e-01, 7.1523e-01, 2.2396e-02, 1.3281e-02],\n",
      "         [4.0000e+00, 6.6406e-01, 4.9102e-01, 1.1458e-02, 1.4844e-02],\n",
      "         [0.0000e+00, 5.2083e-01, 8.0664e-01, 1.4583e-02, 2.7344e-02],\n",
      "         [0.0000e+00, 6.2760e-01, 5.0781e-01, 1.4583e-02, 1.7188e-02],\n",
      "         [3.0000e+00, 5.4193e-01, 6.8594e-01, 2.0312e-02, 2.5000e-02],\n",
      "         [4.0000e+00, 2.4245e-01, 2.6836e-01, 2.3438e-02, 1.7969e-02],\n",
      "         [1.0000e+00, 6.5938e-01, 5.9766e-01, 1.9792e-02, 2.8125e-02],\n",
      "         [0.0000e+00, 4.9766e-01, 2.9844e-01, 1.4062e-02, 3.4375e-02],\n",
      "         [0.0000e+00, 3.2370e-01, 7.1211e-01, 1.9271e-02, 2.5781e-02],\n",
      "         [3.0000e+00, 6.0938e-01, 6.3711e-01, 1.4583e-02, 3.6719e-02],\n",
      "         [4.0000e+00, 5.6615e-01, 7.6328e-01, 2.2917e-02, 1.8750e-02],\n",
      "         [5.0000e+00, 7.2240e-01, 3.5586e-01, 2.2917e-02, 1.9531e-02],\n",
      "         [4.0000e+00, 3.9922e-01, 1.7383e-01, 1.3021e-02, 3.3594e-02],\n",
      "         [4.0000e+00, 5.6797e-01, 4.4414e-01, 2.1354e-02, 1.6406e-02],\n",
      "         [5.0000e+00, 5.3464e-01, 5.6133e-01, 1.9271e-02, 2.5781e-02],\n",
      "         [3.0000e+00, 4.3906e-01, 3.0898e-01, 1.9792e-02, 2.2656e-02],\n",
      "         [1.0000e+00, 6.2552e-01, 2.7969e-01, 1.5625e-02, 1.5625e-02],\n",
      "         [1.0000e+00, 5.3255e-01, 4.0195e-01, 1.4062e-02, 2.4219e-02],\n",
      "         [1.0000e+00, 5.7578e-01, 6.4961e-01, 1.1979e-02, 1.9531e-02],\n",
      "         [3.0000e+00, 5.4193e-01, 4.5430e-01, 1.7188e-02, 3.0469e-02],\n",
      "         [4.0000e+00, 6.4661e-01, 7.1484e-01, 2.2396e-02, 2.1875e-02],\n",
      "         [4.0000e+00, 5.8411e-01, 5.7930e-01, 2.2396e-02, 1.6406e-02],\n",
      "         [2.0000e+00, 7.5469e-01, 4.5039e-01, 1.5625e-02, 2.8906e-02],\n",
      "         [5.0000e+00, 5.2474e-01, 3.3320e-01, 1.5104e-02, 2.2656e-02],\n",
      "         [5.0000e+00, 6.1250e-01, 1.2266e-01, 1.3542e-02, 2.5000e-02],\n",
      "         [3.0000e+00, 3.0755e-01, 2.7227e-01, 1.1979e-02, 3.3594e-02],\n",
      "         [5.0000e+00, 7.0938e-01, 3.3711e-01, 1.8750e-02, 3.3594e-02],\n",
      "         [5.0000e+00, 6.8411e-01, 7.0781e-01, 2.4479e-02, 2.5000e-02],\n",
      "         [1.0000e+00, 3.5417e-01, 5.7305e-01, 2.0833e-02, 1.7969e-02],\n",
      "         [3.0000e+00, 5.4974e-01, 2.5742e-01, 1.3021e-02, 3.3594e-02],\n",
      "         [0.0000e+00, 5.1484e-01, 8.9844e-01, 1.5104e-02, 1.5625e-02],\n",
      "         [4.0000e+00, 6.2500e-01, 4.2930e-01, 2.0833e-02, 2.7344e-02],\n",
      "         [5.0000e+00, 5.8542e-01, 2.5352e-01, 1.7708e-02, 2.4219e-02],\n",
      "         [3.0000e+00, 6.5807e-01, 5.0352e-01, 2.0312e-02, 1.9531e-02],\n",
      "         [0.0000e+00, 5.6302e-01, 1.8281e-01, 1.5625e-02, 1.7188e-02],\n",
      "         [2.0000e+00, 5.3490e-01, 2.7305e-01, 1.9792e-02, 3.0469e-02],\n",
      "         [0.0000e+00, 3.9115e-01, 5.3242e-01, 1.0417e-02, 3.0469e-02],\n",
      "         [3.0000e+00, 5.3828e-01, 3.0469e-01, 1.4062e-02, 2.0312e-02],\n",
      "         [2.0000e+00, 7.2135e-01, 6.0859e-01, 1.5625e-02, 2.1875e-02],\n",
      "         [2.0000e+00, 5.5651e-01, 5.5937e-01, 2.3438e-02, 1.7188e-02],\n",
      "         [2.0000e+00, 3.4688e-01, 8.6094e-01, 2.2917e-02, 1.7188e-02],\n",
      "         [5.0000e+00, 5.9740e-01, 7.0430e-01, 2.1875e-02, 2.7344e-02],\n",
      "         [5.0000e+00, 4.7292e-01, 5.9492e-01, 1.6667e-02, 3.2031e-02],\n",
      "         [0.0000e+00, 2.5417e-01, 3.2930e-01, 2.2917e-02, 1.7969e-02],\n",
      "         [2.0000e+00, 3.4036e-01, 2.7930e-01, 1.1979e-02, 2.8906e-02],\n",
      "         [4.0000e+00, 5.0937e-01, 4.7109e-01, 1.5625e-02, 2.3438e-02],\n",
      "         [5.0000e+00, 7.2161e-01, 5.7539e-01, 1.8229e-02, 1.9531e-02],\n",
      "         [4.0000e+00, 5.4766e-01, 4.1406e-01, 2.1354e-02, 1.4062e-02],\n",
      "         [2.0000e+00, 3.8698e-01, 5.5352e-01, 2.3958e-02, 2.2656e-02],\n",
      "         [5.0000e+00, 7.8151e-01, 6.4062e-01, 1.3021e-02, 1.7188e-02],\n",
      "         [0.0000e+00, 5.8490e-01, 2.7734e-01, 1.3542e-02, 2.5000e-02],\n",
      "         [4.0000e+00, 6.0234e-01, 3.8984e-01, 2.2396e-02, 1.7188e-02],\n",
      "         [5.0000e+00, 5.0703e-01, 2.3281e-01, 1.0937e-02, 1.7188e-02],\n",
      "         [3.0000e+00, 5.4167e-01, 6.1953e-01, 1.8750e-02, 2.0312e-02],\n",
      "         [0.0000e+00, 5.8047e-01, 3.5156e-01, 2.3438e-02, 1.4062e-02],\n",
      "         [5.0000e+00, 4.6198e-01, 7.5508e-01, 1.5625e-02, 2.1094e-02],\n",
      "         [1.1000e+01, 5.1823e-01, 6.4609e-01, 1.4583e-02, 2.1875e-02],\n",
      "         [8.0000e+00, 5.1719e-01, 1.9883e-01, 1.9792e-02, 2.8906e-02],\n",
      "         [1.1000e+01, 5.0807e-01, 1.7305e-01, 2.2396e-02, 2.7344e-02],\n",
      "         [9.0000e+00, 2.9688e-01, 5.8555e-01, 2.1875e-02, 2.2656e-02],\n",
      "         [1.1000e+01, 6.2526e-01, 3.5625e-01, 2.1354e-02, 2.1875e-02],\n",
      "         [8.0000e+00, 2.9818e-01, 6.9883e-01, 1.4062e-02, 3.2031e-02],\n",
      "         [1.1000e+01, 5.3490e-01, 5.2148e-01, 2.1875e-02, 2.5781e-02]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"banana train\")\n",
    "print(train_iter)\n",
    "for features, target in train_iter:\n",
    "    print(features[0])\n",
    "    print(target[0])\n",
    "print(\"our train\")\n",
    "print(new_train_iter)\n",
    "for features, target in new_train_iter:\n",
    "    print(features)\n",
    "    print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_to_tensor = transforms.Compose([\n",
    "    # transforms.Resize(size=(500,500)),\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "dataset_path = \"./data\"\n",
    "\n",
    "train_set = RisikoDataset(dataset_dir=dataset_path,\n",
    "                          mode=\"train\", transform=img_to_tensor)\n",
    "val_set = RisikoDataset(dataset_dir=dataset_path,\n",
    "                        mode=\"val\", transform=img_to_tensor)\n",
    "test_set = RisikoDataset(dataset_dir=dataset_path,\n",
    "                         mode=\"test\", transform=img_to_tensor)\n",
    "\n",
    "\n",
    "def train_loader(batch_size):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "new_train_iter, _ = train_loader(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 5],\n",
      "        [ 0],\n",
      "        [ 2],\n",
      "        [ 0],\n",
      "        [ 6],\n",
      "        [ 6],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [ 9],\n",
      "        [ 6],\n",
      "        [ 8],\n",
      "        [10],\n",
      "        [ 8],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 6]], dtype=torch.int32), tensor([[0.5246, 0.7028, 0.0352, 0.0972],\n",
      "        [0.4676, 0.7007, 0.0336, 0.0514],\n",
      "        [0.5184, 0.5979, 0.0461, 0.0569],\n",
      "        [0.5676, 0.3924, 0.0508, 0.0403],\n",
      "        [0.3504, 0.6590, 0.0508, 0.0569],\n",
      "        [0.4352, 0.9417, 0.0344, 0.0806],\n",
      "        [0.6609, 0.5611, 0.0406, 0.0917],\n",
      "        [0.5773, 0.7590, 0.0312, 0.0875],\n",
      "        [0.7379, 0.2771, 0.0477, 0.0569],\n",
      "        [0.7367, 0.3514, 0.0516, 0.0694],\n",
      "        [0.6625, 0.4521, 0.0500, 0.0569],\n",
      "        [0.5684, 0.7021, 0.0523, 0.0597],\n",
      "        [0.6879, 0.5708, 0.0477, 0.0556],\n",
      "        [0.2492, 0.4771, 0.0406, 0.0597],\n",
      "        [0.5645, 0.6826, 0.0477, 0.0569],\n",
      "        [0.5887, 0.4167, 0.0445, 0.0722],\n",
      "        [0.5383, 0.2486, 0.0453, 0.0917]]))\n",
      "tensor([[ 5.0000,  0.5246,  0.7028,  0.0352,  0.0972],\n",
      "        [ 0.0000,  0.4676,  0.7007,  0.0336,  0.0514],\n",
      "        [ 2.0000,  0.5184,  0.5979,  0.0461,  0.0569],\n",
      "        [ 0.0000,  0.5676,  0.3924,  0.0508,  0.0403],\n",
      "        [ 6.0000,  0.3504,  0.6590,  0.0508,  0.0569],\n",
      "        [ 6.0000,  0.4352,  0.9417,  0.0344,  0.0806],\n",
      "        [ 6.0000,  0.6609,  0.5611,  0.0406,  0.0917],\n",
      "        [ 7.0000,  0.5773,  0.7590,  0.0312,  0.0875],\n",
      "        [ 9.0000,  0.7379,  0.2771,  0.0477,  0.0569],\n",
      "        [ 9.0000,  0.7367,  0.3514,  0.0516,  0.0694],\n",
      "        [ 6.0000,  0.6625,  0.4521,  0.0500,  0.0569],\n",
      "        [ 8.0000,  0.5684,  0.7021,  0.0523,  0.0597],\n",
      "        [10.0000,  0.6879,  0.5708,  0.0477,  0.0556],\n",
      "        [ 8.0000,  0.2492,  0.4771,  0.0406,  0.0597],\n",
      "        [ 6.0000,  0.5645,  0.6826,  0.0477,  0.0569],\n",
      "        [ 7.0000,  0.5887,  0.4167,  0.0445,  0.0722],\n",
      "        [ 6.0000,  0.5383,  0.2486,  0.0453,  0.0917]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_15620\\160284762.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return (img.float(), torch.tensor(output_dict))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m         img_draw\u001b[39m.\u001b[39mrectangle([x0, y0, x1, y1], outline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m     display(img)\n\u001b[1;32m---> 26\u001b[0m draw_bboxes_on_image(train_set, random\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, \u001b[39mlen\u001b[39;49m(train_set)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m, in \u001b[0;36mdraw_bboxes_on_image\u001b[1;34m(dataset, index)\u001b[0m\n\u001b[0;32m      3\u001b[0m     tensor_to_img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mToPILImage()])\n\u001b[0;32m      4\u001b[0m     img \u001b[39m=\u001b[39m tensor_to_img(img)\n\u001b[1;32m----> 5\u001b[0m     bboxes: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m labels[\u001b[39m\"\u001b[39;49m\u001b[39mboxes\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m      7\u001b[0m     img_draw \u001b[39m=\u001b[39m ImageDraw\u001b[39m.\u001b[39mDraw(img)\n\u001b[0;32m     10\u001b[0m \u001b[39m#    bboxes = bboxes * torch.tensor([1280, 720, 1280, 720]) # this depends on image size, we might want to generalize this\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def draw_bboxes_on_image(dataset: RisikoDataset, index: int):\n",
    "    img, labels = dataset.__getitem__(index)\n",
    "    tensor_to_img = transforms.Compose([transforms.ToPILImage()])\n",
    "    img = tensor_to_img(img)\n",
    "    bboxes: torch.Tensor = labels[\"boxes\"]\n",
    "\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "\n",
    "\n",
    "#    bboxes = bboxes * torch.tensor([1280, 720, 1280, 720]) # this depends on image size, we might want to generalize this\n",
    "    bboxes = bboxes * torch.tensor([1920, 1280, 1920, 1280])\n",
    "\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        bbox = bboxes[i]\n",
    "\n",
    "        x0 = bbox[0] - bbox[2] / 2\n",
    "        x1 = bbox[0] + bbox[2] / 2\n",
    "        y0 = bbox[1] - bbox[3] / 2\n",
    "        y1 = bbox[1] + bbox[3] / 2\n",
    "\n",
    "        img_draw.rectangle([x0, y0, x1, y1], outline=\"red\")\n",
    "\n",
    "    display(img)\n",
    "\n",
    "\n",
    "draw_bboxes_on_image(train_set, random.randint(0, len(train_set)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device, net = d2l.try_gpu(), TinySSD(num_classes=12)\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.2, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "bbox_loss = nn.L1Loss(reduction='none')\n",
    "\n",
    "\n",
    "def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks):\n",
    "    batch_size, num_classes = cls_preds.shape[0], cls_preds.shape[2]\n",
    "    cls = cls_loss(cls_preds.reshape(-1, num_classes),\n",
    "                   cls_labels.reshape(-1)).reshape(batch_size, -1).mean(dim=1)\n",
    "    bbox = bbox_loss(bbox_preds * bbox_masks,\n",
    "                     bbox_labels * bbox_masks).mean(dim=1)\n",
    "    return cls + bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_eval(cls_preds, cls_labels):\n",
    "    # Because the class prediction results are on the final dimension,\n",
    "    # `argmax` needs to specify this dimension\n",
    "    return float((cls_preds.argmax(dim=-1).type(\n",
    "        cls_labels.dtype) == cls_labels).sum())\n",
    "\n",
    "\n",
    "def bbox_eval(bbox_preds, bbox_labels, bbox_masks):\n",
    "    return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m metric \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mAccumulator(\u001b[39m4\u001b[39m)\n\u001b[0;32m      9\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfor\u001b[39;00m features, target \u001b[39min\u001b[39;00m new_train_iter:\n\u001b[0;32m     11\u001b[0m     timer\u001b[39m.\u001b[39mstart()\n\u001b[0;32m     12\u001b[0m     trainer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\Programming\\Python\\DeepLearning\\deepl_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Programming\\Python\\DeepLearning\\deepl_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Programming\\Python\\DeepLearning\\deepl_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Programming\\Python\\DeepLearning\\deepl_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[65], line 42\u001b[0m, in \u001b[0;36mRisikoDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     38\u001b[0m bboxes \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([x0, y0, x1, y1])\n\u001b[0;32m     40\u001b[0m \u001b[39m#print((torch.from_numpy(classes).type(\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m#    torch.IntTensor), torch.from_numpy(bboxes)))\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m output_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mconcat((torch\u001b[39m.\u001b[39;49mfrom_numpy(classes)\u001b[39m.\u001b[39;49mtype(\n\u001b[0;32m     43\u001b[0m     torch\u001b[39m.\u001b[39;49mIntTensor), bboxes), \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m \u001b[39m#print(output_dict)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs_dir \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages[idx])\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"240.554688pt\" height=\"173.477344pt\" viewBox=\"0 0 240.554688 173.477344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-06-21T12:46:58.666586</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 173.477344 \n",
       "L 240.554688 173.477344 \n",
       "L 240.554688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"md86e1f862d\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md86e1f862d\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(22.151563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md86e1f862d\" x=\"69.163125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(61.211563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md86e1f862d\" x=\"108.223125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(100.271563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md86e1f862d\" x=\"147.283125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(139.331563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md86e1f862d\" x=\"186.343125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(178.391563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md86e1f862d\" x=\"225.403125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(217.451563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m9a8fb93aa4\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9a8fb93aa4\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 153.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9a8fb93aa4\" x=\"30.103125\" y=\"121.879219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 125.678438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9a8fb93aa4\" x=\"30.103125\" y=\"94.159219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 97.958438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9a8fb93aa4\" x=\"30.103125\" y=\"66.439219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 70.238438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9a8fb93aa4\" x=\"30.103125\" y=\"38.719219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 42.518438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9a8fb93aa4\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs, timer = 5, d2l.Timer()\n",
    "animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                        legend=['class error', 'bbox mae'])\n",
    "net = net.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    # Sum of training accuracy, no. of examples in sum of training accuracy,\n",
    "    # Sum of absolute error, no. of examples in sum of absolute error\n",
    "    metric = d2l.Accumulator(4)\n",
    "    net.train()\n",
    "    for features, target in new_train_iter:\n",
    "        timer.start()\n",
    "        trainer.zero_grad()\n",
    "        print(\"TARGET\", target)\n",
    "        X, Y = features.to(device), target.to(device)\n",
    "        # Generate multiscale anchor boxes and predict their classes and\n",
    "        # offsets\n",
    "        anchors, cls_preds, bbox_preds = net(X)\n",
    "        print(\"NET\", (anchors, cls_preds, bbox_preds))\n",
    "        # Label the classes and offsets of these anchor boxes\n",
    "        bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, Y)\n",
    "        print(\"TARGET\", bbox_labels, bbox_masks, cls_labels)\n",
    "        input()\n",
    "        # Calculate the loss function using the predicted and labeled values\n",
    "        # of the classes and offsets\n",
    "        l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,   \n",
    "                      bbox_masks)\n",
    "        l.mean().backward()\n",
    "        trainer.step()\n",
    "        metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(),\n",
    "                   bbox_eval(bbox_preds, bbox_labels, bbox_masks),\n",
    "                   bbox_labels.numel())\n",
    "    cls_err, bbox_mae = 1 - metric[0] / metric[1], metric[2] / metric[3]\n",
    "    animator.add(epoch + 1, (cls_err, bbox_mae))\n",
    "print(f'class err {cls_err:.2e}, bbox mae {bbox_mae:.2e}')\n",
    "print(f'{len(new_train_iter.dataset) / timer.stop():.1f} examples/sec on '\n",
    "      f'{str(device)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
